{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee9c36f-3fd9-42b8-a5b6-a5a4de1e5cdd",
   "metadata": {
    "id": "0ee9c36f-3fd9-42b8-a5b6-a5a4de1e5cdd"
   },
   "source": [
    "## Imports\n",
    "\n",
    "你可以通过[PyTorch安装页面](https://pytorch.org/get-started/locally/)在各种平台上安装PyTorch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf25ad-8e15-4692-a496-dc69b83a2f00",
   "metadata": {
    "id": "98cf25ad-8e15-4692-a496-dc69b83a2f00",
    "outputId": "20f50a6c-5886-422a-bc6b-7fb43c1cabb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查版本\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e369e44-8cea-4171-87f4-93bf421155c1",
   "metadata": {
    "id": "9e369e44-8cea-4171-87f4-93bf421155c1",
    "outputId": "f0b23064-9f3a-49b7-f60b-82f2b6ee7abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "# 也可以导入常见的缩写 \"nn\" 代表 \"神经网络\"\n",
    "from torch import nn\n",
    "\n",
    "# PyTorch中几乎所有东西都被称为 \"模块\"（您通过将模块堆叠在一起来构建神经网络）\n",
    "this_is_a_module = nn.Linear(in_features=1,\n",
    "                             out_features=1)\n",
    "print(type(this_is_a_module))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b206a-6869-4d33-b313-e952aef82adf",
   "metadata": {
    "id": "d89b206a-6869-4d33-b313-e952aef82adf"
   },
   "source": [
    "### 数据导入\n",
    "\n",
    "由于大多数机器学习都是在数据中寻找模式，因此了解如何在PyTorch中处理数据集是很重要的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cf16f-f713-4a5a-8666-a622695eb612",
   "metadata": {
    "id": "5a6cf16f-f713-4a5a-8666-a622695eb612"
   },
   "outputs": [],
   "source": [
    "# 导入PyTorch数据集（您可以在这里存储您的数据）和数据加载器（您可以在这里加载您的数据）\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58418977-bdb1-4dfb-858c-3d99e5d0ef77",
   "metadata": {
    "id": "58418977-bdb1-4dfb-858c-3d99e5d0ef77"
   },
   "source": [
    "## 创建张量\n",
    "\n",
    "PyTorch的主要用途之一是加速深度学习计算。\n",
    "\n",
    "而深度学习通常涉及对大型张量（大型、多维度的数字集合）进行操作。\n",
    "\n",
    "PyTorch有许多方法来创建张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c9952-5783-4ade-8c92-06b4393139ef",
   "metadata": {
    "id": "ce6c9952-5783-4ade-8c92-06b4393139ef"
   },
   "outputs": [],
   "source": [
    "# 创建一维张量\n",
    "scalar = torch.tensor(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4f286-a8e6-4db0-8d5e-0c7aaf3b7c2b",
   "metadata": {
    "id": "f3f4f286-a8e6-4db0-8d5e-0c7aaf3b7c2b"
   },
   "outputs": [],
   "source": [
    "# 创建随机张量\n",
    "random_tensor = torch.rand(size=(3, 4)) # 这将创建一个大小为3x4的张量，但您可以根据需要调整形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17bde1-c03d-4f7c-ab2a-d24f59161cf6",
   "metadata": {
    "id": "bf17bde1-c03d-4f7c-ab2a-d24f59161cf6"
   },
   "outputs": [],
   "source": [
    "# 张量相乘\n",
    "random_tensor_1 = torch.rand(size=(3, 4))\n",
    "random_tensor_2 = torch.rand(size=(3, 4))\n",
    "random_tensor_3 = random_tensor_1 * random_tensor_2 # PyTorch支持大多数Python中的数学运算符（+、*、-、/）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51efe1-609a-40c0-94a2-1f6c816599ef",
   "metadata": {
    "id": "3f51efe1-609a-40c0-94a2-1f6c816599ef"
   },
   "source": [
    "## 领域库\n",
    "\n",
    "根据您正在处理的具体问题，PyTorch具有几个领域库。\n",
    "\n",
    "- **[TorchVision](https://pytorch.org/vision/stable/index.html)** — PyTorch的计算机视觉库。\n",
    "- **[TorchText](https://pytorch.org/text/stable/index.html)** — PyTorch的内置文本领域库。\n",
    "- [**TorchAudio**](https://pytorch.org/audio/stable/index.html) — PyTorch的音频领域库。\n",
    "- **[TorchRec](https://pytorch.org/torchrec/)** — PyTorch的最新内置领域库，用于通过深度学习驱动推荐引擎。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353bfa2-d950-4f23-98c3-d29ff7c85e85",
   "metadata": {
    "id": "5353bfa2-d950-4f23-98c3-d29ff7c85e85"
   },
   "outputs": [],
   "source": [
    "# 基础计算机视觉库\n",
    "import torchvision\n",
    "\n",
    "# TorchVision的其他组件（预定义数据集、预训练模型和图像转换）\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044f35e-068f-4664-a16c-b3150a842ce2",
   "metadata": {
    "id": "d044f35e-068f-4664-a16c-b3150a842ce2"
   },
   "source": [
    "### 文本和 NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b5026-fb0e-42f6-a50f-e4171a379c86",
   "metadata": {
    "id": "328b5026-fb0e-42f6-a50f-e4171a379c86"
   },
   "outputs": [],
   "source": [
    "# 基础文本和自然语言处理库\n",
    "import torchtext\n",
    "\n",
    "# TorchText的其他组件（预定义数据集、预训练模型和文本转换）\n",
    "from torchtext import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2409d640-a768-4423-a37c-3f4f2472b319",
   "metadata": {
    "id": "2409d640-a768-4423-a37c-3f4f2472b319"
   },
   "source": [
    "### 视频和语言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956edd5a-291b-41d5-b7fa-507a171171dc",
   "metadata": {
    "id": "956edd5a-291b-41d5-b7fa-507a171171dc"
   },
   "outputs": [],
   "source": [
    "# 基础音频和语音处理库\n",
    "import torchaudio\n",
    "\n",
    "# TorchAudio的其他组件（预定义数据集、预训练模型和音频转换）\n",
    "from torchaudio import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf19cae-f18b-4bb9-af99-56725a739df7",
   "metadata": {
    "id": "0cf19cae-f18b-4bb9-af99-56725a739df7"
   },
   "source": [
    "### 推荐系统\n",
    "\n",
    "> **注意：** 此库目前处于 beta 版本，查看[GitHub页面以获取安装信息](https://github.com/pytorch/torchrec#installation)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb24f63-13c9-406c-9608-f66042a99f87",
   "metadata": {
    "id": "ddb24f63-13c9-406c-9608-f66042a99f87"
   },
   "outputs": [],
   "source": [
    "# # 基础推荐系统库\n",
    "# import torchrec\n",
    "\n",
    "# # TorchRec的其他组件\n",
    "# from torchrec import datasets, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc7202-271a-4473-94fc-4945319bda37",
   "metadata": {
    "id": "f0dc7202-271a-4473-94fc-4945319bda37"
   },
   "source": [
    "## 设备相关的代码（在CPU、GPU或MPS上使用PyTorch）\n",
    "\n",
    "深度学习的大部分工作涉及对张量进行计算。\n",
    "\n",
    "在GPU（通常来自NVIDIA的图形处理单元）上进行张量计算通常比在CPU（计算机处理单元）上快得多。\n",
    "\n",
    "MPS代表“Metal Performance Shader”，这是苹果的GPU（M1、M1 Pro、M2等）。\n",
    "\n",
    "建议在您可用的最快硬件上进行训练，通常为：NVIDIA GPU（`\"cuda\"`）> MPS设备（`\"mps\"`）> CPU（`\"cpu\"`）。\n",
    "\n",
    "* 若要了解有关如何在NVIDIA GPU（使用CUDA）上运行PyTorch的更多信息，请参阅[PyTorch文档部分2：在GPU上运行PyTorch](https://pytorch.org/docs/stable/cuda.html)。\n",
    "* 若要了解如何使用MPS后端（在Mac GPU上运行PyTorch）运行PyTorch，请参阅[PyTorch文档](https://pytorch.org/docs/stable/notes/mps.html)。\n",
    "\n",
    "> **注意：** 建议在工作流程开始时设置设备无关的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f561d-63f7-4609-86eb-868750eb8b8a",
   "metadata": {
    "id": "081f561d-63f7-4609-86eb-868750eb8b8a",
    "outputId": "b6f6776e-68f4-49ae-980e-66a5f853537a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# 设置设备相关代码\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\" # 无GPU\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f1f37-470f-486a-9a71-b7128ae295a9",
   "metadata": {
    "id": "208f1f37-470f-486a-9a71-b7128ae295a9"
   },
   "source": [
    "### 将张量发送到目标设备\n",
    "\n",
    "您可以通过`.to(\"device_name\")`方法将对象（模型和张量）在PyTorch中移动到不同的设备上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6c29a-5d0a-45e1-9dde-547356e1366e",
   "metadata": {
    "id": "7dc6c29a-5d0a-45e1-9dde-547356e1366e",
    "outputId": "20c8951a-8efd-42f0-a1c3-48e56b2c1270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# 创建张量\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(x.device) # 初始化 CPU\n",
    "\n",
    "# 将张量输送到目标设备\n",
    "x = x.to(device)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27d062-281b-4628-9374-c276640aceb8",
   "metadata": {
    "id": "9d27d062-281b-4628-9374-c276640aceb8"
   },
   "source": [
    "## 设置随机数种子\n",
    "\n",
    "许多机器学习和深度学习涉及将张量中的随机数进行形状调整，以发现/表示真实数据中的模式。\n",
    "\n",
    "然而，有时您可能需要“可重现”的随机性。\n",
    "\n",
    "为此，您可以设置随机种子，请参阅[可重现性（试图消除随机性）](https://www.learnpytorch.io/00_pytorch_fundamentals/#reproducibility-trying-to-take-the-random-out-of-random)了解更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de557ce2-60df-4945-a57a-a8dc5e7de756",
   "metadata": {
    "id": "de557ce2-60df-4945-a57a-a8dc5e7de756",
    "outputId": "65c6a43d-bb9f-426c-c98b-412db0e7dc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 设置随机种子（您可以将其设置为任何喜欢的数字，它将使随机性带有该数字的“风味”）。\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 创建两个随机张量\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(42) # 再次设置随机数种子\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea594e-6ae6-4637-97bb-e52cd537df64",
   "metadata": {
    "id": "e3ea594e-6ae6-4637-97bb-e52cd537df64"
   },
   "source": [
    "也能在 GPU 上设置随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2499098-9311-40b2-8ff3-63d433064aaa",
   "metadata": {
    "id": "b2499098-9311-40b2-8ff3-63d433064aaa"
   },
   "outputs": [],
   "source": [
    "# 在 GPU 上设置随机数种子\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd5fba-9578-481b-850e-a968ade7700a",
   "metadata": {
    "id": "3efd5fba-9578-481b-850e-a968ade7700a"
   },
   "source": [
    "## 神经网络\n",
    "\n",
    "PyTorch拥有非常全面的预构建神经网络组件库（在PyTorch生态系统中，其中许多被称为“模块”）。\n",
    "\n",
    "在基本层面上，神经网络是层的堆叠。每个这些层对输入执行某种操作，并产生输出。\n",
    "\n",
    "这些层如何堆叠在一起将取决于您正在处理的问题。\n",
    "\n",
    "机器学习中最活跃的研究领域之一是如何将神经网络层堆叠在一起（对此的最佳答案不断变化）。\n",
    "\n",
    "PyTorch中绝大多数神经网络组件都包含在[`torch.nn`包](https://pytorch.org/docs/stable/nn.html)中（`nn`是神经网络的缩写）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b039b-c4ad-4f47-bad7-75ac8ca7db12",
   "metadata": {
    "id": "888b039b-c4ad-4f47-bad7-75ac8ca7db12"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497528d9-9fef-4323-8438-b7a298ed7ea3",
   "metadata": {
    "id": "497528d9-9fef-4323-8438-b7a298ed7ea3"
   },
   "source": [
    "### 线性层\n",
    "\n",
    "PyTorch内置了几种[线性层](https://pytorch.org/docs/stable/nn.html#linear-layers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79047b27-3752-4e36-b7a9-a8e95bac20c4",
   "metadata": {
    "id": "79047b27-3752-4e36-b7a9-a8e95bac20c4"
   },
   "outputs": [],
   "source": [
    "# 创建一个输入特征为10，输出特征为10的线性层\n",
    "linear_layer = nn.Linear(in_features=10,\n",
    "                         out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972c605-39b4-43e4-aba4-02d9527cbbde",
   "metadata": {
    "id": "4972c605-39b4-43e4-aba4-02d9527cbbde"
   },
   "outputs": [],
   "source": [
    "# 创建Identity\n",
    "identity_layer = nn.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115ee4f-67a1-4adb-92e1-7604ccbb4b62",
   "metadata": {
    "id": "9115ee4f-67a1-4adb-92e1-7604ccbb4b62"
   },
   "source": [
    "### CNN\n",
    "\n",
    "PyTorch拥有[几种内置的卷积层](https://pytorch.org/docs/stable/nn.html#convolution-layers)。\n",
    "\n",
    "卷积层的命名通常遵循`torch.nn.ConvXd`的格式，其中`X`可以是`1`、`2`或`3`。\n",
    "\n",
    "`X`值代表卷积操作的维度数量，例如，对于单维度文本，`1`表示，对于二维图像（高度x宽度）为`2`，对于视频等三维对象（视频被视为具有时间维度的一系列图像，高度x宽度x时间）为`3`。\n",
    "\n",
    "> **注意：** 您可以在[03. PyTorch计算机视觉部分7.2：构建卷积神经网络（CNN）](https://www.learnpytorch.io/03_pytorch_computer_vision/#7-model-2-building-a-convolutional-neural-network-cnn)中了解如何使用PyTorch构建用于计算机视觉的卷积神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a8c21-cc87-4ebe-9a03-68f9765647c2",
   "metadata": {
    "id": "882a8c21-cc87-4ebe-9a03-68f9765647c2"
   },
   "outputs": [],
   "source": [
    "# 创建1维卷积层\n",
    "conv1d = nn.Conv1d(in_channels=1,\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d96033-75e4-4695-ad39-c488bb0a5038",
   "metadata": {
    "id": "93d96033-75e4-4695-ad39-c488bb0a5038"
   },
   "outputs": [],
   "source": [
    "# 创建2维卷积层\n",
    "conv2d = nn.Conv2d(in_channels=3, # 图片的3通道\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b697f0-b80b-4dc7-a7d9-b771dad6c171",
   "metadata": {
    "id": "b0b697f0-b80b-4dc7-a7d9-b771dad6c171"
   },
   "outputs": [],
   "source": [
    "# 创建3维卷积层\n",
    "conv3d = nn.Conv3d(in_channels=3,\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042dabb-9f18-4cd1-916b-b0d864048b7e",
   "metadata": {
    "id": "6042dabb-9f18-4cd1-916b-b0d864048b7e"
   },
   "source": [
    "### Transformer \n",
    "\n",
    "PyTorch内置了Transformer层，正如在论文[Attention Is All You Need](https://arxiv.org/abs/1706.03762)中描述的那样。\n",
    "\n",
    "使用内置的PyTorch Transformer层具有潜在的加速优势，这要归功于[PyTorch的BetterTransformer](https://pytorch.org/blog/a-better-transformer-for-fast-transformer-encoder-inference/)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcab8b8-defc-4d8c-8d75-c7826f200dd1",
   "metadata": {
    "id": "0bcab8b8-defc-4d8c-8d75-c7826f200dd1"
   },
   "outputs": [],
   "source": [
    "# 创建一个Transformer模型（基于论文“Attention Is All You Need” - https://arxiv.org/abs/1706.03762）\n",
    "transformer_model = nn.Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba384ef7-d6f4-4969-80da-f477634ea96f",
   "metadata": {
    "id": "ba384ef7-d6f4-4969-80da-f477634ea96f"
   },
   "outputs": [],
   "source": [
    "# 创建Transformer 编码器单元\n",
    "transformer_encoder = nn.TransformerEncoderLayer(d_model=768, # embedding dimension\n",
    "                                                 nhead=12) # number of attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e761141-0967-4804-a71b-03994132f865",
   "metadata": {
    "id": "6e761141-0967-4804-a71b-03994132f865"
   },
   "outputs": [],
   "source": [
    "# 堆叠Transformer编码器单元\n",
    "transformer_encoder_stack = nn.TransformerEncoder(encoder_layer=transformer_encoder, # from above\n",
    "                                                  num_layers=6) # 6 Transformer encoders stacked on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc3a0f-b4c4-47a2-ab29-999e66b5ed08",
   "metadata": {
    "id": "afdc3a0f-b4c4-47a2-ab29-999e66b5ed08"
   },
   "outputs": [],
   "source": [
    "# 创建Transformer解码器单元\n",
    "transformer_decoder = nn.TransformerDecoderLayer(d_model=768,\n",
    "                                                 nhead=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf68ba3-2f4b-454f-a5fe-3707bf52fa9d",
   "metadata": {
    "id": "0bf68ba3-2f4b-454f-a5fe-3707bf52fa9d"
   },
   "outputs": [],
   "source": [
    "# 堆叠Transformer解码器单元\n",
    "transformer_decoder_stack = nn.TransformerDecoder(decoder_layer=transformer_decoder, # from above\n",
    "                                                  num_layers=6) # 6 Transformer decoders stacked on top of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6397f85-2263-47b1-b720-c3d46bf0eaef",
   "metadata": {
    "id": "a6397f85-2263-47b1-b720-c3d46bf0eaef"
   },
   "source": [
    "### RNN\n",
    "\n",
    "PyTorch内置支持[循环神经网络层](https://pytorch.org/docs/stable/nn.html#recurrent-layers)，如[长短期记忆（LSTM）](https://en.wikipedia.org/wiki/Long_short-term_memory)和[门控循环单元（GRU）](https://en.wikipedia.org/wiki/Gated_recurrent_unit)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbfdc0-3673-42c8-b075-62664cc4be85",
   "metadata": {
    "id": "aabbfdc0-3673-42c8-b075-62664cc4be85"
   },
   "outputs": [],
   "source": [
    "# 创建LSTM单元\n",
    "lstm_cell = nn.LSTMCell(input_size=10, # can adjust as necessary\n",
    "                        hidden_size=10) # can adjust as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67845c-55b5-4e67-9058-699075644b7c",
   "metadata": {
    "id": "df67845c-55b5-4e67-9058-699075644b7c"
   },
   "outputs": [],
   "source": [
    "# 堆叠LSTM单元\n",
    "lstm_stack = nn.LSTM(input_size=10,\n",
    "                     hidden_size=10,\n",
    "                     num_layers=3) # 3 single LSTM cells stacked on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421579e-ab99-4b5f-be73-2a7f11f70d36",
   "metadata": {
    "id": "e421579e-ab99-4b5f-be73-2a7f11f70d36"
   },
   "outputs": [],
   "source": [
    "# 创建GRU单元\n",
    "gru_cell = nn.GRUCell(input_size=10, # can adjust as necessary\n",
    "                      hidden_size=10) # can adjust as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083284c1-501a-466a-b4e9-901a079f958c",
   "metadata": {
    "id": "083284c1-501a-466a-b4e9-901a079f958c"
   },
   "outputs": [],
   "source": [
    "# 堆叠GRU单元\n",
    "gru_stack = nn.GRU(input_size=10,\n",
    "                   hidden_size=10,\n",
    "                   num_layers=3) # 3 single GRU cells stacked on top of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087611c-aae7-41fe-8397-03e01c885ade",
   "metadata": {
    "id": "5087611c-aae7-41fe-8397-03e01c885ade"
   },
   "source": [
    "### 激活函数\n",
    "\n",
    "[激活函数](https://en.wikipedia.org/wiki/Activation_function)经常在神经网络的层之间使用，以为线性（直线）函数添加非线性（非直线）能力。\n",
    "\n",
    "实质上，神经网络通常由大量的线性和非线性函数组成。\n",
    "\n",
    "PyTorch内置了[多种非线性激活函数](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)，存放在`torch.nn`中。\n",
    "\n",
    "其中一些最常见的是：\n",
    "* `nn.ReLU` - 也被称为[修正线性单元](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))。\n",
    "* `nn.Sigmoid` - 也被称为[sigmoid函数](https://en.wikipedia.org/wiki/Sigmoid_function)。\n",
    "* `nn.Softmax` - 也被称为[softmax函数](https://en.wikipedia.org/wiki/Softmax_function)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38581ec6-ed57-4c2f-89bb-f99193939cac",
   "metadata": {
    "id": "38581ec6-ed57-4c2f-89bb-f99193939cac"
   },
   "outputs": [],
   "source": [
    "# ReLU\n",
    "relu = nn.ReLU()\n",
    "\n",
    "# Sigmoid\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# Softmax\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38e1c3-1159-439d-ad3b-0db1b7fa3d12",
   "metadata": {
    "id": "bf38e1c3-1159-439d-ad3b-0db1b7fa3d12"
   },
   "source": [
    "### 损失函数\n",
    "\n",
    "损失函数衡量了模型的“错误程度”。也就是说，它的预测偏离了它们应该的位置有多远。\n",
    "\n",
    "理想情况下，通过训练、数据和优化函数，这个损失值应尽可能地降低。\n",
    "\n",
    "在PyTorch中（以及深度学习中），损失函数通常也被称为：标准、成本函数。\n",
    "\n",
    "PyTorch内置了[多种损失函数](https://pytorch.org/docs/stable/nn.html#loss-functions)，存放在`torch.nn`中。\n",
    "\n",
    "其中一些最常见的是：\n",
    "* [`nn.L1Loss`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss) - 也称为MAE或[平均绝对误差](https://en.wikipedia.org/wiki/Mean_absolute_error)（这种损失通常用于回归问题或预测数值，例如房价）。\n",
    "* [`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) - 也称为L2Loss或[均方误差](https://en.wikipedia.org/wiki/Mean_squared_error)（这种损失通常用于回归问题或预测数值，例如房价）。\n",
    "* [`nn.BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss) - 也称为[二元交叉熵](https://en.wikipedia.org/wiki/Cross_entropy)，这种损失函数通常用于二分类问题（将某样东西分类为一种或另一种）。\n",
    "* [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) - 这种损失函数通常用于多类别分类问题（将某样东西分类为一种或另一种）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe3146-759e-4f2f-aeea-ec1ecb506ad2",
   "metadata": {
    "id": "7ffe3146-759e-4f2f-aeea-ec1ecb506ad2"
   },
   "outputs": [],
   "source": [
    "# L1Loss\n",
    "loss_fn = nn.L1Loss() # also known as MAE or mean absolute error\n",
    "\n",
    "# MSELoss\n",
    "loss_fn = nn.MSELoss() # also known as MSE or mean squared error\n",
    "\n",
    "# Binary cross entropy (for binary classification problems)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Cross entropy (for multi-class classification problems)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5746cf2-2ff9-4621-a681-df36cac3beb1",
   "metadata": {
    "id": "e5746cf2-2ff9-4621-a681-df36cac3beb1"
   },
   "source": [
    "### 优化器\n",
    "\n",
    "优化器的任务是以减少损失函数值为目标，调整神经网络的权重。\n",
    "\n",
    "PyTorch内置了[多种优化函数](https://pytorch.org/docs/stable/optim.html)，存放在`torch.optim`模块中。\n",
    "\n",
    "其中两个主要的优化器函数包括：\n",
    "* [`torch.optim.SGD(lr=0.1, params=model.parameters())`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) - SGD也称为[随机梯度下降](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)（`lr`代表“学习率”，即在每一步中调整神经网络权重的乘数，小值=小调整，大值=大调整）。\n",
    "* [`torch.optim.Adam(lr=0.001, params=model.parameters())`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) - Adam优化器（`params`代表“模型参数”，换句话说，是您希望优化函数在训练期间优化的模型参数/权重）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec2382-d11d-40d4-afb7-fec01f4abccb",
   "metadata": {
    "id": "e6ec2382-d11d-40d4-afb7-fec01f4abccb"
   },
   "outputs": [],
   "source": [
    "# 创建baseline\n",
    "model = nn.Transformer()\n",
    "\n",
    "# SGD (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(lr=0.1, # set the learning rate (required)\n",
    "                            params=model.parameters()) # tell the optimizer what parameters to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a27e05-12fe-42f1-83aa-1e488f594373",
   "metadata": {
    "id": "75a27e05-12fe-42f1-83aa-1e488f594373"
   },
   "outputs": [],
   "source": [
    "# 创建baseline\n",
    "model = nn.Transformer()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(lr=0.001, # set the learning rate (required)\n",
    "                             params=model.parameters()) # tell the optimizer what parameters to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bef22-4a74-487e-b8c6-18cb90bb0964",
   "metadata": {
    "id": "3e4bef22-4a74-487e-b8c6-18cb90bb0964"
   },
   "source": [
    "## 端到端模型\n",
    "让我们在一个快速的端到端工作流中将所有内容整合在一起。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01_a_pytorch_workflow.png\" width=950 alt=\"从数据到构建模型到拟合模型到评估模型的PyTorch工作流\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24805c73-7558-4d27-aba1-a78fce5312ce",
   "metadata": {
    "id": "24805c73-7558-4d27-aba1-a78fce5312ce"
   },
   "source": [
    "### 创建数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed19d7-0e4e-42e8-ad80-8504033b3f6d",
   "metadata": {
    "id": "7fed19d7-0e4e-42e8-ad80-8504033b3f6d",
    "outputId": "29b72178-181c-4613-c7da-ffbd9a449b85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1) # data\n",
    "y = weight * X + bias # labels (want model to learn from data to predict these)\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbfae76-edbf-470b-8686-8e12e30bbc8b",
   "metadata": {
    "id": "7dbfae76-edbf-470b-8686-8e12e30bbc8b",
    "outputId": "8d20a380-5fcf-4be9-dbd2-0382383dcc51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train/test split\n",
    "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b525ca1-bcc3-48c9-8b6b-ead556a50e9c",
   "metadata": {
    "id": "8b525ca1-bcc3-48c9-8b6b-ead556a50e9c"
   },
   "source": [
    "### 创建模型\n",
    "\n",
    "在PyTorch中创建模型有两种主要方式：\n",
    "1. 子类化`torch.nn.Module` - 代码量较多，但非常灵活，模型必须实现一个`forward()`方法。\n",
    "2. 使用`torch.nn.Sequential` - 代码量较少，但灵活性较低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f102f8c-ad12-48b4-bfc6-bde5eb945bc8",
   "metadata": {
    "id": "0f102f8c-ad12-48b4-bfc6-bde5eb945bc8",
    "outputId": "c92abf5c-19d9-4633-a1a5-deb0536a415a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegressionModel(\n",
       "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('linear_layer.weight', tensor([[0.5025]])),\n",
       "              ('linear_layer.bias', tensor([-0.0722]))]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Option 1 - subclass torch.nn.Module\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use nn.Linear() for creating the model parameters\n",
    "        self.linear_layer = nn.Linear(in_features=1,\n",
    "                                      out_features=1)\n",
    "\n",
    "    # Define the forward computation (input data x flows through nn.Linear())\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "model_0, model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37ecd4-6258-404d-8dc3-149cd8540af3",
   "metadata": {
    "id": "eb37ecd4-6258-404d-8dc3-149cd8540af3"
   },
   "source": [
    "现在让我们使用`torch.nn.Sequential`来创建与上面相同的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c357fd-68ef-428e-90ae-ed225dad2e4d",
   "metadata": {
    "id": "e2c357fd-68ef-428e-90ae-ed225dad2e4d",
    "outputId": "2b1da7a7-ac6a-4313-bef4-da65ecfec001"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('0.weight', tensor([[0.9905]])), ('0.bias', tensor([0.9053]))]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Option 2 - use torch.nn.Sequential\n",
    "model_1 = torch.nn.Sequential(\n",
    "    nn.Linear(in_features=1,\n",
    "              out_features=1))\n",
    "\n",
    "model_1, model_1.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11692983-6190-4d51-9d4e-5293f4205988",
   "metadata": {
    "id": "11692983-6190-4d51-9d4e-5293f4205988"
   },
   "source": [
    "### 设置损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d1c6d-a60f-4642-994d-7e0cb822164b",
   "metadata": {
    "id": "5c3d1c6d-a60f-4642-994d-7e0cb822164b"
   },
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), # optimize newly created model's parameters\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2f55e-8037-4942-8b74-0a09a3f4b007",
   "metadata": {
    "id": "d0b2f55e-8037-4942-8b74-0a09a3f4b007"
   },
   "source": [
    "### 创建训练和测试循环\n",
    "\n",
    "我们的目标是降低模型的损失（模型的预测与实际数据的差异程度）。\n",
    "\n",
    "如果我们的训练/测试循环实现正确，并且模型能够学习数据中的模式，那么训练和测试损失应该会降低。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064882b-5fc7-4479-ad81-0dc0686ea711",
   "metadata": {
    "id": "0064882b-5fc7-4479-ad81-0dc0686ea711",
    "outputId": "784c3401-8a85-46b5-8ba8-d18404b187ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 100 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 200 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 300 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 400 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 500 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 600 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 700 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 800 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 900 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 设置epochs的数量\n",
    "epochs = 1000\n",
    "\n",
    "# 将数据放置在可用设备上\n",
    "# 如果不进行此操作，会出现错误（不是所有数据都在目标设备上）\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# 将模型放置在可用设备上\n",
    "# 如果不进行此操作，会出现错误（模型不在目标设备上）\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### 训练\n",
    "    model_1.train() # 默认情况下，构造后会进入训练模式\n",
    "\n",
    "    # 1. 前向传播\n",
    "    y_pred = model_1(X_train)\n",
    "\n",
    "    # 2. 计算损失\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. 梯度清零\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. 反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. 更新优化器\n",
    "    optimizer.step()\n",
    "\n",
    "    ### 测试\n",
    "    model_1.eval() # 将模型放置在评估模式以进行测试（推断）\n",
    "    # 1. 前向传播\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_1(X_test)\n",
    "\n",
    "        # 2. 计算损失\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af70942c-b2de-47ae-a266-d8097a124600",
   "metadata": {
    "id": "af70942c-b2de-47ae-a266-d8097a124600"
   },
   "source": [
    "## 额外资源\n",
    "\n",
    "上述列表并不详尽。\n",
    "\n",
    "以下是了解更多信息的一些好地方：\n",
    "\n",
    "* [PyTorch官方速查表](https://pytorch.org/tutorials/beginner/ptcheat.html)。\n",
    "* [从零到精通学习PyTorch课程](https://dbourke.link/ZTMPyTorch) - 一门全面但适合初学者的深入学习PyTorch的课程，从基础知识到将模型部署到实际环境中以供他人使用。\n",
    "* [PyTorch性能调优指南](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html) - PyTorch团队提供的一个关于如何调优PyTorch模型性能的资源。\n",
    "* [PyTorch额外资源](https://www.learnpytorch.io/pytorch_extra_resources/) - 一个由精选资源组成的清单，用于扩展PyTorch并了解更多有关深度学习工程方面的知识。\n",
    "* [vahidk的Effective PyTorch](https://github.com/vahidk/EffectivePyTorch) - 一个GitHub存储库，以简单明了的方式提供了PyTorch的一些主要功能概述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab32691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
